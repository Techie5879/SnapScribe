# Machine Learning Resources
This file contains a curated list of resources related to the machine learning aspect of the SnapScribe. These resources can be useful for understanding the techniques used in sequence modeling, computer vision, and image captioning.  
It also details the expected workflow when developing a real world ML project. PRs are expected to follow the workflow and participants will be required to understand (atleast some, because its definitely not a good idea to dive into a rabbit hole of studying and never applying) aspects.

## Online Courses, Resources, YT Playlists
[Coursera - Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction) - Basic intro to ML topics including stuff like Linear Regression, Logistic Regression etc. The first course in this specialization won't be of much direct use to this project but it is still recommended to complete it. The second course has intro to Neural Networks and CNNs which is relevant to this project.

[Coursera - Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) - A comprehensive specialization covering various topics in deep learning, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and sequence modeling.

[Fast.ai - Practical Deep Learning for Coders](https://www.fast.ai/) - A practical course that teaches deep learning by building real-world applications. It provides hands-on experience with state-of-the-art techniques.

[Learn PyTorch](https://www.learnpytorch.io/) - An excellent resource to give you a flavour of the complete life-cycle of an ML Project, paper-replication and model deployment. Also, go through all the extra resources if you can!

[PyTorch in 25hrs](https://www.youtube.com/watch?v=V_xro1bcAuA&t=523s&pp=ygUIcHl0b3JjaCA%3D) - Not meant to be finished in a day! Take your time.


## Research Papers (Optional)
Something that you will often need to do while learning ML topics or implementing things, is reading research papers. So while this part of the project isn't mandatory considering the timeline, take a look at a bit of the following research paper (remember: you don't have to understand everything you read, trust me there will be a lot that you don't understand. Never hesitate to Google topics to try to learn more about them). 

**NOTE**: It is recommended to only try to read the below once you know the basics of Neural Networks, CNNs, RNNs, LSTMs, and have heard/watched something introductory about Transformer Attention Models. Remember not to dive too deep into the mathematics for every topic. You can just dip your toes and understand the basics and how to implement each using Tensorflow/PyTorch. The basics are all that is required.

[Show and Tell: A Neural Image Caption Generator](https://arxiv.org/pdf/1411.4555) - The original research paper by Vinyals et al. that introduces the concept of using neural networks for generating image captions.

[Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/pdf/1707.07998) - A research paper by Anderson et al. that proposes an attention mechanism for image captioning, allowing the model to focus on relevant image regions.

Blogs and Tutorials
Machine Learning Mastery - A blog by Jason Brownlee offering a wealth of tutorials, articles, and resources on various machine learning topics.

Towards Data Science - An online platform featuring a wide range of data science and machine learning articles, tutorials, and case studies.
